{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business 510  files\n",
      "entertainment 386  files\n",
      "politics 417  files\n",
      "sport 511  files\n",
      "tech 401  files\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"bbc\" #Folder directory\n",
    "all_files= os.listdir(path)\n",
    "all_data = []\n",
    "class_lable = -1\n",
    "for sub_file in all_files:\n",
    "   \n",
    "    sub_position = path+ '/' + sub_file\n",
    "    sub_all_files = os.listdir(sub_position)\n",
    "#     Every_subfile = []\n",
    "    class_lable += 1\n",
    "    sum_num = 0\n",
    "    for file in sub_all_files:\n",
    "        position = sub_position+ '/' + file\n",
    "        sum_num += 1\n",
    "        \n",
    "        with open(position, \"r\",encoding='unicode_escape') as f:\n",
    "            lines = f.readlines()\n",
    "            for line in lines:\n",
    "                if line == '\\n':\n",
    "                    line = line.strip()\n",
    "                else:\n",
    "                    all_data.append((line.strip(),class_lable))\n",
    "    print(sub_file,sum_num,' files')\n",
    "#     all_data.append(Every_subfile)             \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12893\n"
     ]
    }
   ],
   "source": [
    "print(len(all_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Data_Train, Data_Test = train_test_split(all_data, test_size = 0.2, random_state = 0)\n",
    "Data_New_Test, Data_New_Dev = train_test_split(Data_Test, test_size = 0.5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10314\n",
      "1289\n",
      "1290\n"
     ]
    }
   ],
   "source": [
    "import random \n",
    "Data_New_Train = Data_Train\n",
    "random.shuffle(Data_New_Train)\n",
    "random.shuffle(Data_New_Test)\n",
    "random.shuffle(Data_New_Dev)\n",
    "print(len(Data_New_Train))\n",
    "print(len(Data_New_Test))\n",
    "print(len(Data_New_Dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('\"For any cultural output to thrive there needs to be some kind of state input to that as well,\" he said. But Kapranos warned against musicians being too closely linked with MPs, at the University of Edinburgh event. \"I think the role of musicians is to question politicians rather than to go to bed with them,\" he said.', 1)\n",
      "(\"The Japanese gaming giant hopes the DS will maintain the firm's pre-eminence in an increasingly-competitive mobile gaming market.\", 4)\n",
      "\n",
      "------\n",
      "\n",
      "(\"At least 10 countries have been affected, with Sri Lanka, Indonesia, India and Thailand among the worst hit. The region's resorts and Western tourists are expected to be among the main claimants.\", 0)\n",
      "(\"LG Card had been threatened with collapse because of its huge debts but the firm's creditors and its former parent have stepped in to rescue it. A consortium of creditors and LG Group, a family owned conglomerate, have each put up $480m to stabilise the firm. LG Card has seven million customers and its collapse would have sent shockwaves through the country's economy.\", 0)\n",
      "\n",
      "------\n",
      "\n",
      "(\"A documentary which takes a candid look at the life of chart-topping singer George Michael will be shown at this year's Berlin Film Festival.\", 1)\n",
      "('The Aviator took four awards in all, also collecting best make-up and hair and production design, while Vera Drake also scooped best costume design. Staunton, who is up for an Oscar for her role in Vera Drake, arrived wearing a green silk and chiffon beaded evening dress. \"Thank you very much. I\\'m so thrilled and so grateful and I\\'m delighted that the success of Vera Drake has boosted sales of hair nets and pinnies, which is very good,\" she said on accepting her award. Her director Leigh, who beat Martin Scorsese to the best director award, told the audience: \"We always say it was a surprise and sometimes I\\'ve said it and not meant it. On this occasion, given the other names, it\\'s a real surprise and an extraordinary honour. \"It\\'s an immense privilege to have been allowed the freedom to make as uncompromising a film as I think Vera Drake is and an epic with such a small budget.\" Best actor Foxx could not make the ceremony, but actress Helen Mirren read out his acceptance speech. \"I\\'m honoured and proud to receive this Bafta. I\\'d like to thank the late Ray Charles himself.\" He apologised for not being in London, joking: \"Unfortunately I\\'m stuck driving a car in LA at gunpoint and I can\\'t get away.\" DiCaprio, who lost out on the best actor Bafta to Foxx, will face him again at the Academy Awards in two weeks\\' time.', 1)\n",
      "\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in Data_New_Train[:2]:\n",
    "    print(line)\n",
    "print(\"\\n------\\n\")\n",
    "for line in Data_New_Test[:2]:\n",
    "    print(line)\n",
    "print(\"\\n------\\n\")\n",
    "for line in Data_New_Dev[:2]:\n",
    "    print(line)\n",
    "print(\"\\n------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import sklearn\n",
    "import operator\n",
    "\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "stopwords=set(nltk.corpus.stopwords.words('english'))\n",
    "stopwords.add(\".\")\n",
    "stopwords.add(\",\")\n",
    "stopwords.add(\"--\")\n",
    "stopwords.add(\"``\")\n",
    "stopwords.add(\"''\")\n",
    "stopwords.add(\"&\")\n",
    "stopwords.add(\"?\")\n",
    "stopwords.add(\"$\")\n",
    "for ch in \"''-)(%:\":\n",
    "    stopwords.add(ch)\n",
    "\n",
    "# Function taken from Session 1\n",
    "def get_list_tokens(string): # Function to retrieve the list of tokens from a string\n",
    "    sentence_split=nltk.tokenize.sent_tokenize(string)\n",
    "    list_tokens=[]\n",
    "    for sentence in sentence_split:\n",
    "        list_tokens_sentence=nltk.tokenize.word_tokenize(sentence)\n",
    "        for token in list_tokens_sentence:\n",
    "            list_tokens.append(lemmatizer.lemmatize(token).lower())\n",
    "    return list_tokens\n",
    "\n",
    "# Function taken from Session 2\n",
    "def get_vector_text(list_vocab,string):\n",
    "    vector_text=np.zeros(len(list_vocab))\n",
    "    list_tokens_string=get_list_tokens(string)\n",
    "    for i, word in enumerate(list_vocab):\n",
    "        if word in list_tokens_string:\n",
    "            vector_text[i]=list_tokens_string.count(word)\n",
    "    return vector_text\n",
    "\n",
    "\n",
    "# Functions slightly modified from Session 2\n",
    "\n",
    "def get_vocabulary(training_set, num_features):\n",
    "    dict_word_frequency={}\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])\n",
    "        for word in sentence_tokens:\n",
    "            if word in stopwords: \n",
    "                continue\n",
    "            if word not in dict_word_frequency: \n",
    "                dict_word_frequency[word]=1\n",
    "            else: \n",
    "                dict_word_frequency[word]+=1\n",
    "    sorted_list = sorted(dict_word_frequency.items(), key=operator.itemgetter(1), reverse=True)[:num_features]\n",
    "    vocabulary=[]\n",
    "    for word,frequency in sorted_list:\n",
    "        vocabulary.append(word)\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "def get_num_vocabulary(training_set, num_features):\n",
    "    dict_word_num={}\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])\n",
    "        for word in sentence_tokens:\n",
    "            sum_num = 0\n",
    "            if word in stopwords: \n",
    "                continue\n",
    "            else:\n",
    "                for ch in word:\n",
    "                    sum_num += 1\n",
    "                dict_word_num[word] = sum_num   \n",
    "\n",
    "    sorted_list = sorted(dict_word_num.items(), key=operator.itemgetter(1), reverse=True)[:num_features]\n",
    "    vocabulary=[]\n",
    "    for word,frequency in sorted_list:\n",
    "        vocabulary.append(word)\n",
    "    return vocabulary\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_ave_num_vocabulary(training_set, num_features):\n",
    "    dict_word_num={}\n",
    "    word_num = 0\n",
    "    all_word_num = 0\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])\n",
    "        for word in sentence_tokens:\n",
    "            word_num += 1\n",
    "            sum_num = 0\n",
    "            if word in stopwords: \n",
    "                continue\n",
    "            else:\n",
    "                for ch in word:\n",
    "                    sum_num += 1\n",
    "                    all_word_num += 1\n",
    "                dict_word_num[word] = sum_num   \n",
    "    ave_num = round(all_word_num/word_num,0)\n",
    "    \n",
    "    vocabulary=[]\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])\n",
    "        for word in sentence_tokens:\n",
    "            if word in stopwords: \n",
    "                continue\n",
    "            elif dict_word_num[word] == ave_num:\n",
    "                if word in vocabulary:\n",
    "                    continue\n",
    "                else:\n",
    "                    vocabulary.append(word)\n",
    "                    \n",
    "    size_test=int(num_features)\n",
    "\n",
    "    list_test_indices=random.sample(range(len(vocabulary)), size_test)\n",
    "    select_vocabulary=[]\n",
    "\n",
    "    for i,example in enumerate(vocabulary):\n",
    "        if i in list_test_indices: \n",
    "            select_vocabulary.append(example)\n",
    "    return select_vocabulary\n",
    "\n",
    "def train_svm_classifier(training_set, vocabulary): \n",
    "    X_train=[]\n",
    "    Y_train=[]\n",
    "    for instance in training_set:\n",
    "        vector_instance=get_vector_text(vocabulary,instance[0])\n",
    "        X_train.append(vector_instance)\n",
    "        Y_train.append(instance[1])\n",
    "  \n",
    "\n",
    "    svm_clf=sklearn.svm.SVC(kernel=\"linear\",gamma='auto')\n",
    "    svm_clf.fit(np.asarray(X_train),np.asarray(Y_train))\n",
    "    return svm_clf\n",
    "\n",
    "# def feature_selection(training_set,vocabulary, num_features):\n",
    "#     X_train=[]\n",
    "#     Y_train=[]\n",
    "#     for instance in training_set:\n",
    "#         vector_instance=get_vector_text(vocabulary,instance[0])\n",
    "#         X_train.append(vector_instance)\n",
    "#         Y_train.append(instance[1])\n",
    "    \n",
    "#     X_new_train = np.asarray(X_train)\n",
    "#     Y_new_train = np.asarray(Y_train)\n",
    "    \n",
    "#     fs_data=SelectKBest(chi2, k=num_features).fit(X_new_train, Y_new_train)\n",
    "#     X_train_fs = fs_data.transform(X_new_train)\n",
    "#     #X_train_new = SelectKBest(chi2, k=500).fit_transform(X_train, Y_train)\n",
    "#     print (\"Size original training matrix: \"+str(X_new_train.shape))\n",
    "#     print (\"Size new training matrix: \"+str(X_train_fs.shape))\n",
    "    \n",
    "#     svm_clf_fs=sklearn.svm.SVC(kernel=\"linear\",gamma='auto') # Change the name here, e.g. 'new sentanalysis_svm_clf', and below if you don't want to replace your old classifier.\n",
    "#     svm_clf_fs.fit(X_train_fs,Y_new_train) #Train the new SVM model. This may take a while.\n",
    "    \n",
    "#     return svm_clf_fs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ave_num_vocabulary_nonum(training_set): # Function to retrieve vocabulary\n",
    "    dict_word_num={}\n",
    "    word_num = 0\n",
    "    all_word_num = 0\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])\n",
    "        for word in sentence_tokens:\n",
    "            word_num += 1\n",
    "            sum_num = 0\n",
    "            if word in stopwords: \n",
    "                continue\n",
    "            else:\n",
    "                for ch in word:\n",
    "                    sum_num += 1\n",
    "                    all_word_num += 1\n",
    "                dict_word_num[word] = sum_num   \n",
    "    ave_num = round(all_word_num/word_num,0)\n",
    "    \n",
    "    vocabulary=[]\n",
    "    for instance in training_set:\n",
    "        sentence_tokens=get_list_tokens(instance[0])\n",
    "        for word in sentence_tokens:\n",
    "            if word in stopwords: \n",
    "                continue\n",
    "            elif dict_word_num[word] == ave_num:\n",
    "                if word in vocabulary:\n",
    "                    continue\n",
    "                else:\n",
    "                    vocabulary.append(word)\n",
    "                    \n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377\n"
     ]
    }
   ],
   "source": [
    "all_ave_num_vocabulary=get_ave_num_vocabulary_nonum(Data_New_Train)\n",
    "print(len(all_ave_num_vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Frequency Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 500: 0.819\n",
      "Accuracy with 1000: 0.846\n",
      "Accuracy with 1500: 0.863\n",
      "Accuracy with 2000: 0.875\n",
      "\n",
      " Frequency best accuracy overall in the dev set is 0.875 with 2000 features.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "\n",
    "Y_dev=[]\n",
    "for instance in Data_New_Dev:\n",
    "    Y_dev.append(instance[1])\n",
    "Y_dev_gold=np.asarray(Y_dev)\n",
    "\n",
    "\n",
    "list_num_features=[500,1000,1500,2000]\n",
    "best_accuracy_dev=0.0\n",
    "for num_features in list_num_features:\n",
    "  # First, we get the vocabulary from the training set and train our svm classifier\n",
    "    vocabulary=get_vocabulary(Data_New_Train, num_features)  \n",
    "    svm_clf=train_svm_classifier(Data_New_Train, vocabulary)\n",
    "  # Then, we transform our dev set into vectors and make the prediction on this set\n",
    "    X_dev=[]\n",
    "    for instance in Data_New_Dev:\n",
    "        vector_instance=get_vector_text(vocabulary,instance[0])\n",
    "        X_dev.append(vector_instance)\n",
    "    X_dev=np.asarray(X_dev)\n",
    "    Y_dev_predictions=svm_clf.predict(X_dev)\n",
    "  # Finally, we get the accuracy results of the classifier\n",
    "    accuracy_dev=accuracy_score(Y_dev_gold, Y_dev_predictions)\n",
    "    print (\"Accuracy with \"+str(num_features)+\": \"+str(round(accuracy_dev,3)))\n",
    "    if accuracy_dev>=best_accuracy_dev:\n",
    "        best_accuracy_dev=accuracy_dev\n",
    "        best_num_features=num_features\n",
    "        frequency_best_vocabulary=vocabulary\n",
    "        frequency_best_svm_clf=svm_clf\n",
    "print (\"\\n Frequency best accuracy overall in the dev set is \"+str(round(best_accuracy_dev,3))+\" with \"+str(best_num_features)+\" features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection(Frequency) and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "Y_test=[]\n",
    "for instance in Data_New_Test:\n",
    "    vector_instance=get_vector_text(frequency_best_vocabulary,instance[0])\n",
    "    X_test.append(vector_instance)\n",
    "    Y_test.append(instance[1])\n",
    "X_test=np.asarray(X_test)\n",
    "Y_test_gold=np.asarray(Y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size original training matrix: (10314, 2000)\n",
      "Size new training matrix: (10314, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "for instance in Data_New_Train:\n",
    "    vector_instance=get_vector_text(frequency_best_vocabulary,instance[0])\n",
    "    X_train.append(vector_instance)\n",
    "    Y_train.append(instance[1])\n",
    "    \n",
    "X_new_train = np.asarray(X_train)\n",
    "Y_new_train = np.asarray(Y_train)\n",
    "    \n",
    "fs_data=SelectKBest(chi2, k=1000).fit(X_new_train, Y_new_train)\n",
    "X_train_fs = fs_data.transform(X_new_train)\n",
    "    \n",
    "print (\"Size original training matrix: \"+str(X_new_train.shape))\n",
    "print (\"Size new training matrix: \"+str(X_train_fs.shape))\n",
    "    \n",
    "frequency_svm_clf_fs=sklearn.svm.SVC(kernel=\"linear\",gamma='auto') \n",
    "frequency_svm_clf_fs.fit(X_train_fs,Y_new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_text_predictions = frequency_svm_clf_fs.predict(fs_data.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.875\n",
      "Recall: 0.87\n",
      "F1-Score: 0.872\n",
      "Accuracy: 0.873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score,f1_score,accuracy_score\n",
    "\n",
    "precision=precision_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "recall=recall_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "f1=f1_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "accuracy=accuracy_score(Y_test_gold, Y_text_predictions)\n",
    "\n",
    "print (\"Precision: \"+str(round(precision,3)))\n",
    "print (\"Recall: \"+str(round(recall,3)))\n",
    "print (\"F1-Score: \"+str(round(f1,3)))\n",
    "print (\"Accuracy: \"+str(round(accuracy,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.85      0.86       260\n",
      "           1       0.88      0.83      0.85       222\n",
      "           2       0.89      0.86      0.87       252\n",
      "           3       0.83      0.93      0.88       296\n",
      "           4       0.91      0.88      0.89       259\n",
      "\n",
      "    accuracy                           0.87      1289\n",
      "   macro avg       0.88      0.87      0.87      1289\n",
      "weighted avg       0.87      0.87      0.87      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "# Y_text_predictions=svm_clf.predict(X_test)\n",
    "print(classification_report(Y_test_gold, Y_text_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Number of words feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 1000: 0.329\n",
      "Accuracy with 2000: 0.396\n",
      "Accuracy with 5000: 0.552\n",
      "Accuracy with 10000: 0.713\n",
      "\n",
      " Number of words vocabulary,best accuracy overall in the dev set is 0.713 with 10000 features.\n"
     ]
    }
   ],
   "source": [
    "list_num_features=[1000,2000,5000,10000]\n",
    "best_accuracy_dev=0.0\n",
    "for num_features in list_num_features:\n",
    "  # First, we get the vocabulary from the training set and train our svm classifier\n",
    "    vocabulary=get_num_vocabulary(Data_New_Train, num_features)  \n",
    "    svm_clf=train_svm_classifier(Data_New_Train, vocabulary)\n",
    "  # Then, we transform our dev set into vectors and make the prediction on this set\n",
    "    X_dev=[]\n",
    "    for instance in Data_New_Dev:\n",
    "        vector_instance=get_vector_text(vocabulary,instance[0])\n",
    "        X_dev.append(vector_instance)\n",
    "    X_dev=np.asarray(X_dev)\n",
    "    Y_dev_predictions=svm_clf.predict(X_dev)\n",
    "  # Finally, we get the accuracy results of the classifier\n",
    "    accuracy_dev=accuracy_score(Y_dev_gold, Y_dev_predictions)\n",
    "    print (\"Accuracy with \"+str(num_features)+\": \"+str(round(accuracy_dev,3)))\n",
    "    if accuracy_dev>=best_accuracy_dev:\n",
    "        best_accuracy_dev=accuracy_dev\n",
    "        best_num_features=num_features\n",
    "        num_best_vocabulary=vocabulary\n",
    "        num_best_svm_clf=svm_clf\n",
    "print (\"\\n Number of words vocabulary,best accuracy overall in the dev set is \"+str(round(best_accuracy_dev,3))+\" with \"+str(best_num_features)+\" features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection(Number of words) and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "Y_test=[]\n",
    "for instance in Data_New_Test:\n",
    "    vector_instance=get_vector_text(num_best_vocabulary,instance[0])\n",
    "    X_test.append(vector_instance)\n",
    "    Y_test.append(instance[1])\n",
    "X_test=np.asarray(X_test)\n",
    "Y_test_gold=np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size original training matrix: (10314, 10000)\n",
      "Size new training matrix: (10314, 1000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "for instance in Data_New_Train:\n",
    "    vector_instance=get_vector_text(num_best_vocabulary,instance[0])\n",
    "    X_train.append(vector_instance)\n",
    "    Y_train.append(instance[1])\n",
    "    \n",
    "X_new_train = np.asarray(X_train)\n",
    "Y_new_train = np.asarray(Y_train)\n",
    "    \n",
    "fs_data=SelectKBest(chi2, k=1000).fit(X_new_train, Y_new_train)\n",
    "X_train_fs = fs_data.transform(X_new_train)\n",
    "    #X_train_new = SelectKBest(chi2, k=500).fit_transform(X_train, Y_train)\n",
    "print (\"Size original training matrix: \"+str(X_new_train.shape))\n",
    "print (\"Size new training matrix: \"+str(X_train_fs.shape))\n",
    "    \n",
    "num_svm_clf_fs=sklearn.svm.SVC(kernel=\"linear\",gamma='auto') # Change the name here, e.g. 'new sentanalysis_svm_clf', and below if you don't want to replace your old classifier.\n",
    "num_svm_clf_fs.fit(X_train_fs,Y_new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.58      0.65       260\n",
      "           1       0.78      0.59      0.67       222\n",
      "           2       0.82      0.65      0.73       252\n",
      "           3       0.54      0.94      0.69       296\n",
      "           4       0.82      0.66      0.73       259\n",
      "\n",
      "    accuracy                           0.69      1289\n",
      "   macro avg       0.74      0.68      0.69      1289\n",
      "weighted avg       0.73      0.69      0.69      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_text_predictions = num_svm_clf_fs.predict(fs_data.transform(X_test))\n",
    "print(classification_report(Y_test_gold, Y_text_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.742\n",
      "Recall: 0.683\n",
      "F1-Score: 0.693\n",
      "Accuracy: 0.694\n"
     ]
    }
   ],
   "source": [
    "precision=precision_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "recall=recall_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "f1=f1_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "accuracy=accuracy_score(Y_test_gold, Y_text_predictions)\n",
    "\n",
    "print (\"Precision: \"+str(round(precision,3)))\n",
    "print (\"Recall: \"+str(round(recall,3)))\n",
    "print (\"F1-Score: \"+str(round(f1,3)))\n",
    "print (\"Accuracy: \"+str(round(accuracy,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Averange length of words feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with 800: 0.464\n",
      "Accuracy with 1000: 0.486\n",
      "Accuracy with 1377: 0.55\n",
      "\n",
      " Averange length of words vocabulary,best accuracy overall in the dev set is 0.55 with 1377 features.\n"
     ]
    }
   ],
   "source": [
    "list_num_features=[800,1000,1377]\n",
    "best_accuracy_dev=0.0\n",
    "for num_features in list_num_features:\n",
    "  # First, we get the vocabulary from the training set and train our svm classifier\n",
    "    vocabulary=get_ave_num_vocabulary(Data_New_Train, num_features)  \n",
    "    svm_clf=train_svm_classifier(Data_New_Train, vocabulary)\n",
    "  # Then, we transform our dev set into vectors and make the prediction on this set\n",
    "    X_dev=[]\n",
    "    for instance in Data_New_Dev:\n",
    "        vector_instance=get_vector_text(vocabulary,instance[0])\n",
    "        X_dev.append(vector_instance)\n",
    "    X_dev=np.asarray(X_dev)\n",
    "    Y_dev_predictions=svm_clf.predict(X_dev)\n",
    "  # Finally, we get the accuracy results of the classifier\n",
    "    accuracy_dev=accuracy_score(Y_dev_gold, Y_dev_predictions)\n",
    "    print (\"Accuracy with \"+str(num_features)+\": \"+str(round(accuracy_dev,3)))\n",
    "    if accuracy_dev>=best_accuracy_dev:\n",
    "        best_accuracy_dev=accuracy_dev\n",
    "        best_num_features=num_features\n",
    "        ave_num_best_vocabulary=vocabulary\n",
    "        ave_num_best_svm_clf=svm_clf\n",
    "print (\"\\n Averange length of words vocabulary,best accuracy overall in the dev set is \"+str(round(best_accuracy_dev,3))+\" with \"+str(best_num_features)+\" features.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection(Averange length of words) and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "Y_test=[]\n",
    "for instance in Data_New_Test:\n",
    "    vector_instance=get_vector_text(ave_num_best_vocabulary,instance[0])\n",
    "    X_test.append(vector_instance)\n",
    "    Y_test.append(instance[1])\n",
    "X_test=np.asarray(X_test)\n",
    "Y_test_gold=np.asarray(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size original training matrix: (10314, 1377)\n",
      "Size new training matrix: (10314, 650)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(gamma='auto', kernel='linear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train=[]\n",
    "Y_train=[]\n",
    "for instance in Data_New_Train:\n",
    "    vector_instance=get_vector_text(ave_num_best_vocabulary,instance[0])\n",
    "    X_train.append(vector_instance)\n",
    "    Y_train.append(instance[1])\n",
    "    \n",
    "X_new_train = np.asarray(X_train)\n",
    "Y_new_train = np.asarray(Y_train)\n",
    "    \n",
    "fs_data=SelectKBest(chi2, k=650).fit(X_new_train, Y_new_train)\n",
    "X_train_fs = fs_data.transform(X_new_train)\n",
    "    #X_train_new = SelectKBest(chi2, k=500).fit_transform(X_train, Y_train)\n",
    "print (\"Size original training matrix: \"+str(X_new_train.shape))\n",
    "print (\"Size new training matrix: \"+str(X_train_fs.shape))\n",
    "    \n",
    "ave_num_svm_clf_fs=sklearn.svm.SVC(kernel=\"linear\",gamma='auto') # Change the name here, e.g. 'new sentanalysis_svm_clf', and below if you don't want to replace your old classifier.\n",
    "ave_num_svm_clf_fs.fit(X_train_fs,Y_new_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.44      0.52       260\n",
      "           1       0.62      0.36      0.46       222\n",
      "           2       0.50      0.42      0.46       252\n",
      "           3       0.40      0.84      0.55       296\n",
      "           4       0.76      0.46      0.58       259\n",
      "\n",
      "    accuracy                           0.52      1289\n",
      "   macro avg       0.59      0.50      0.51      1289\n",
      "weighted avg       0.58      0.52      0.51      1289\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_text_predictions = ave_num_svm_clf_fs.predict(fs_data.transform(X_test))\n",
    "print(classification_report(Y_test_gold, Y_text_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.586\n",
      "Recall: 0.504\n",
      "F1-Score: 0.511\n",
      "Accuracy: 0.518\n"
     ]
    }
   ],
   "source": [
    "precision=precision_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "recall=recall_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "f1=f1_score(Y_test_gold, Y_text_predictions, average='macro')\n",
    "accuracy=accuracy_score(Y_test_gold, Y_text_predictions)\n",
    "\n",
    "print (\"Precision: \"+str(round(precision,3)))\n",
    "print (\"Recall: \"+str(round(recall,3)))\n",
    "print (\"F1-Score: \"+str(round(f1,3)))\n",
    "print (\"Accuracy: \"+str(round(accuracy,3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python39_64_bit",
   "language": "python",
   "name": "python39_64_bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
